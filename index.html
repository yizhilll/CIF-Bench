<!DOCTYPE html>
<html>
<head>
  <title>CIF-Bench</title>
    <style>
        .hidden {
            display: none;
        }
    </style>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <script src="https://kit.fontawesome.com/f8ddf9854a.js" crossorigin="anonymous"></script>
  <meta charset="utf-8">
  <meta name="description"
        content="CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models">
  <meta name="keywords" content="CIF-Bench, LLM, LLM Evaluation, Instruction Following, Large Language Model, artificial intelligence, AI, AGI, artificial general intelligence">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title> CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models</title>

  <link rel="icon" href="./c_static/images/cif_bench_logo.png">

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="./static/css/leaderboard.css">

  <!-- <link href="https://unpkg.com/tabulator-tables@5.5.2/dist/css/tabulator_bulma.min.css" rel="stylesheet">
  <script type="text/javascript" src="https://unpkg.com/tabulator-tables@5.5.2/dist/js/tabulator.min.js"></script> -->
  <script type="text/javascript" src="static/js/sort-table.js" defer></script>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/question_card.js"></script>
  <script src="./data/results/data_setting.js" defer></script>
  <script src="./data/results/model_scores.js" defer></script>
  <script src="./visualizer/data/data_public.js" defer></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
</head>
<body class="cmmmu-container">

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://tiger-ai-lab.github.io/MAmmoTH/">
            <b>MAmmoTH</b> <p style="font-size:18px; display: inline; margin-left: 5px;">🔥</p>
          </a>
          <a class="navbar-item" href="https://osu-nlp-group.github.io/TableLlama/">
            TableLlama 
            <a class="navbar-item" href="https://osu-nlp-group.github.io/MagicBrush/">
              MagicBrush
            </a>
            <a class="navbar-item" href="https://osu-nlp-group.github.io/Mind2Web/">
              Mind2Web
            </a>
          </a>
          
          </a>
        </div>
      </div>
    </div>

  </div> -->
</nav>


<section class="hero cmmmu-green">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title is-bold">
            <img src="c_static/images/cif_bench_logo.png" style="width:1em;vertical-align: middle" alt="Logo"/> 
            <span class="cmmmu" style="vertical-align: middle">CIF-Bench</span>
            </h1>
          <h2 class="subtitle is-3 publication-subtitle">
            A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models
          
          <!-- </h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://xiangyue9607.github.io/" style="text-decoration: none; color: inherit;">Xiang Yue*<sup style="color:#6fbf73;">†,1</sup></a>,
            </span>
            <span class="author-block">
              <a href="https://yuanshengni.github.io/" style="text-decoration: none; color: inherit;">Yuansheng Ni*<sup style="color:#ffac33;">2</sup></a>
              ,
            </span>
            <span class="author-block">
              <a href="https://drogozhang.github.io/" style="text-decoration: none; color: inherit;">Kai Zhang*<sup style="color:#ed4b82;">3</sup></a>
              ,
            </span>
            <span class="author-block">Tianyu Zheng*<sup style="color:#007bff;">4</sup>,</span><br>
            <span class="author-block">Ruoqi Liu<sup style="color:#ed4b82;">3</sup>,</span>
            <span class="author-block">Ge Zhang<sup style="color:#ffac33;">2</sup>,</span>
            <span class="author-block">Samuel Stevens<sup style="color:#ed4b82;">3</sup>,</span>
            <span class="author-block">Dongfu Jiang<sup style="color:#ffac33;">2</sup>,</span>
            <span class="author-block">Weiming Ren<sup style="color:#ffac33;">2</sup>,</span>
            <span class="author-block">Yuxuan Sun<sup style="color:#007bff;">4</sup>,</span>
            <span class="author-block">Cong Wei<sup style="color:#ffac33;">2</sup>,</span>
            <span class="author-block">Botao Yu<sup style="color:#ed4b82;">3</sup>,</span>
            <span class="author-block">Ruibin Yuan<sup style="color:#ffac33;">5</sup>,</span>
            <span class="author-block">Renliang Sun<sup style="color:#ffac33;">2</sup>,</span>
            <span class="author-block">Ming Yin<sup style="color:#9b51e0;">7</sup>,</span>
            <span class="author-block">Boyuan Zheng<sup style="color:#ed4b82;">3</sup>,</span>
            <span class="author-block">Zhenzhu Yang<sup style="color:#007bff;">4</sup>,</span>
            <span class="author-block">Yibo Liu<sup style="color:#ed4b82;">6</sup>,</span>
            <span class="author-block">Wenhao Huang<sup style="color:#007bff;">4</sup>,</span><br>
            <span class="author-block">
              <a href="https://web.cse.ohio-state.edu/~sun.397/" style="text-decoration: none; color: inherit;">Huan Sun*<sup style="color:#ed4b82;">3</sup></a>
              ,
          </span>
          <span class="author-block">
              <a href="https://ysu1989.github.io/" style="text-decoration: none; color: inherit;">Yu Su*<sup style="color:#ed4b82;">†,3</sup></a>
              ,
          </span>
          <span class="author-block">
              <a href="https://wenhuchen.github.io/" style="text-decoration: none; color: inherit;">Wenhu Chen*<sup style="color:#ffac33;">†,2</sup></a>
              
          </span>
          
          </div>
          
          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color:#6fbf73;">1</sup>IN.AI Research,</span>
            <span class="author-block"><sup style="color:#ffac33;">2</sup>University of Waterloo,</span>
            <span class="author-block"><sup style="color:#ed4b82;">3</sup>The Ohio State University,</span>
            <span class="author-block"><sup style="color:#007bff;">4</sup>Independent,</span></br>
            <span class="author-block"><sup style="color:#ffac33;">5</sup>Carnegie Mellon University,</span>
            <span class="author-block"><sup style="color:#ed4b82;">6</sup>University of Victoria,</span>
            <span class="author-block"><sup style="color:#9b51e0;">7</sup>Princeton University</span>
          </div>

          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block">*Core Contributors</span><br>
            <span class="author-block">†Corresponding to:</span>
            <span class="author-block"><a href="mailto:xiangyue.work@gmail.com">xiangyue.work@gmail.com</a>,</span>
            <span class="author-block"><a href="mailto:su.809@osu.edu">su.809@osu.edu</a>,</span>
            <span class="author-block"><a href="mailto:wenhuchen@uwaterloo.ca">wenhuchen@uwaterloo.ca</a></span>
          </div> -->

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <!-- @PAN TODO: change links -->
                <a href="https://arxiv.org/abs"
                   class="external-link button is-normal is-rounded">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/papers"
                   class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <p style="font-size:18px">🤗</p>
                  </span>
                  <span>HF Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/datasets"
                   class="external-link button is-normal is-rounded">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">🤗</p>
                      <!-- 🔗 -->
                  </span>
                  <span>Dataset</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com"
                   class="external-link button is-normal is-rounded">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              
              <!-- Twitter Link. -->
              <span class="link-block">
                <a href="https://twitter.com/GeZhang86038849/status/1749660947223044325"
                   class="external-link button is-normal is-rounded">
                  <span class="icon has-text-white">
                    <i class="fa-brands fa-x-twitter"></i>
                      <!-- <p style="font-size:18px">🌐</p> -->
                  </span>
                  <span>Twitter</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<style>
  .center {
    display: block;
    margin-left: auto;
    margin-right: auto;
    width: 80%;
  }
  </style>
<section class="hero teaser">
  <div class="container is-max-desktop">
    <!-- <div class="hero-body">
      <img src="static/images/tease_scores.png" alt="Examples from the dataset"/>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Nerfies</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div> -->
      <!-- <div class="box m-5"> -->
        <div class="content has-text-centered">
          <img src="c_static/images/overview_cifbench.png" alt="Task Category Distribution" width="50%"/>
          <p> Overview of the CIF-Bench. It is distinguished by its <b>comprehensiveness</b>. The radii have three groups, determined by the number of tasks contained (≤ 10, ≤ 20, and > 20).</p>
        </div>
      <!-- </div> -->
    </div>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- <h2 class="title ">🔔News</h2> -->
        <div class="content has-text-justified">
          <!-- <p>
              <b>🔥[2023-12-04]: Our evaluation server for the test set is now available on <a href="https://eval.ai/web/challenges/challenge-page/2179/overview">EvalAI</a>. We welcome all submissions and look forward to your participation! 😆</b>
          </p> -->
      </div>      
        <h2 class="title is-3">Abstract </h2>
        <div class="content has-text-justified">
          <p>
            The advancement of large language models (LLMs) has enhanced the ability to generalize across a wide range of unseen natural language processing (NLP) tasks through instructionfollowing. Yet, their effectiveness often diminishes in low-resource languages like Chinese, exacerbated by biased evaluations from data leakage, casting doubt on their true generalizability to new linguistic territories. In response, we introduce the Chinese Instruction-Following Benchmark (CIF-Bench), designed to evaluate the zero-shot generalizability of LLMs to the Chinese language. CIF-Bench comprises 150 tasks and 15,000 input-output pairs, developed by native speakers to test complex reasoning and Chinese cultural nuances across 20 categories. To mitigate evaluation bias, we release only half of the dataset publicly, with the remainder kept private, and introduce diversified instructions to minimize score variance, totaling 45,000 data instances. Our evaluation of 28 selected LLMs reveals a noticeable performance gap, with the best model scoring only 52.9%, highlighting the limitations of LLMs in less familiar language and task contexts. This work not only uncovers the current limitations of LLMs in handling Chinese language tasks but also sets a new standard for future LLM generalizability research, pushing towards the development of more adaptable, culturally informed, and linguistically diverse models        
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<!-- DATASET SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 mmmu">
    <img src="c_static/images/cif_bench_logo.png" style="width:1em;vertical-align: middle" alt="Logo"/>
    <span class="mmmu" style="vertical-align: middle">CIF-Bench</span>
  </h1>
  </div>
</section>

<!-- <section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p> -->
            
<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <!-- <div class="column is-full-width has-text-centered"> -->
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            we introduce the Chinese Instruction-Following Benchmark (CIF-Bench), a novel benchmark designed for the zero-shot generalizability evaluation of LLMs, with Chinese serving as an insightful example for multilingual transferred instruction-following tasks. Our benchmark comprises 150 tasks and 15, 000 input-output pairs, with the assistance of native speaker annotators, ensuring the inclusion of human-authored tasks that are not only challenging but also naturally expressed. A significant portion (38.7%) of these tasks are designed to test a model’s complex natural language inference (NLI) and reasoning capabilities, as well as drawing upon Chinese culture spread across 20 distinct categories. In an effort to mitigate future evaluation biases from data leakage, we decide to publicly release only half of the data instances, reserving the rest as a private dataset to maintain an impartial benchmark. Furthermore, CIF-Bench enhances its robustness by introducing 5 variations of instructions per task, using these to diminish score variance in private split evaluations. CIF-Bench also pioneers a model-based automatic pipeline designed to tackle the inherent challenges of evaluating open-ended natural language generation outputs. </p>
          <img src="c_static/images/teaser.png" alt="A large language model can tackle English task translated to Chinese, but fail to respond to instruction originally in Chinese." class="center">
          <br>
          <p>
            By selecting a range of popular LLMs that support Chinese for evaluation, we aim to depict the limits of current instruction-following capabilities in language transfer contexts as the many models follow an English-oriented pre-training paradigm (Huang et al., 2023b). Our findings reveal that even the best-performing model achieves a score of only 52.9% on CIF-Bench, underscoring the gap that exists when LLMs are confronted with tasks in a less-familiar language and unseen data instances. We find that this performance decrement is particularly noticeable in scenarios involving unseen tasks and unseen input-output pairs, contrasting with the models’ performance on existing Chinese datasets and translated English-language tasks. Such results suggest that while LLMs exhibit impressive generalizability in a context more aligned with observed data, their effectiveness diminishes when faced with the dual challenges of unacquainted languages and novel tasks.          </p>
          <p>
            To summarize our contributions, we: (1) Present a new benchmark that addresses a critical gap in existing NLP research by focusing on the generalizability of LLMs to an underrepresented language in terms of training and evaluation resources; (2) Construct an instruction-following evaluation dataset with 150 tasks and 45, 000 data samples, and release half of the input-output pairs for future LLM evaluation research; (3) Provide an in-depth analysis of 28 LLMs, revealing their limitations in adapting to less familiar languages and task contexts, offering insights into where improvements are needed for instruction-following generalizability. </p>

        
        </div>
    </div>
    </div>

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Leaderboard</h2>
          
          
          <style>
              .scrollable-table {
                  overflow-y: auto;
                  height: 600px; /* Adjust the height as needed */
              }
              table {
                  border-collapse: collapse;
                  width: 100%;
              }
              th, td {
                  border: 1px solid #dddddd;
                  text-align: left;
                  padding: 8px;
              }
              th {
                  background-color: #f2f2f2;
              }
          </style>
          
          <div class="scrollable-table">
              <table border="1" class="dataframe">
            <thead>
              <tr style="text-align: right;">
                <th>Model Name</th>
                <th>Overall</th>
                <th>Chinese Culture</th>
                <th>Classification</th>
                <th>Code</th>
                <th>Commonsense</th>
                <th>Creative NLG</th>
                <th>Evaluation</th>
                <th>Grammar</th>
                <th>Linguistic</th>
                <th>Motion Detection</th>
                <th>NER</th>
                <th>NLI</th>
                <th>QA</th>
                <th>Reasoning</th>
                <th>Role Playing</th>
                <th>Sentiment</th>
                <th>Structured Data</th>
                <th>Style Transfer</th>
                <th>Summarization</th>
                <th>Toxic</th>
                <th>Translation</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Baichuan2-13B-Chat</td>
                <td>0.529</td>
                <td>0.520</td>
                <td>0.674</td>
                <td>0.333</td>
                <td>0.641</td>
                <td>0.497</td>
                <td>0.686</td>
                <td>0.542</td>
                <td>0.528</td>
                <td>0.578</td>
                <td>0.563</td>
                <td>0.632</td>
                <td>0.569</td>
                <td>0.515</td>
                <td>0.752</td>
                <td>0.624</td>
                <td>0.459</td>
                <td>0.462</td>
                <td>0.332</td>
                <td>0.441</td>
                <td>0.273</td>
              </tr>
              <tr>
                <td>Qwen-72B-Chat</td>
                <td>0.519</td>
                <td>0.486</td>
                <td>0.630</td>
                <td>0.296</td>
                <td>0.634</td>
                <td>0.508</td>
                <td>0.634</td>
                <td>0.458</td>
                <td>0.520</td>
                <td>0.494</td>
                <td>0.550</td>
                <td>0.626</td>
                <td>0.565</td>
                <td>0.528</td>
                <td>0.762</td>
                <td>0.613</td>
                <td>0.496</td>
                <td>0.459</td>
                <td>0.282</td>
                <td>0.608</td>
                <td>0.271</td>
              </tr>
              <tr>
                <td>Yi-34B-Chat</td>
                <td>0.512</td>
                <td>0.483</td>
                <td>0.606</td>
                <td>0.347</td>
                <td>0.623</td>
                <td>0.497</td>
                <td>0.598</td>
                <td>0.480</td>
                <td>0.490</td>
                <td>0.575</td>
                <td>0.525</td>
                <td>0.619</td>
                <td>0.554</td>
                <td>0.494</td>
                <td>0.757</td>
                <td>0.580</td>
                <td>0.472</td>
                <td>0.439</td>
                <td>0.346</td>
                <td>0.514</td>
                <td>0.259</td>
              </tr>
              <tr>
                <td>Qwen-14B-Chat</td>
                <td>0.500</td>
                <td>0.481</td>
                <td>0.582</td>
                <td>0.307</td>
                <td>0.614</td>
                <td>0.494</td>
                <td>0.645</td>
                <td>0.428</td>
                <td>0.475</td>
                <td>0.496</td>
                <td>0.513</td>
                <td>0.616</td>
                <td>0.548</td>
                <td>0.507</td>
                <td>0.764</td>
                <td>0.583</td>
                <td>0.469</td>
                <td>0.453</td>
                <td>0.283</td>
                <td>0.575</td>
                <td>0.262</td>
              </tr>
              <tr>
                <td>Deepseek-Llm-67B-Chat</td>
                <td>0.471</td>
                <td>0.467</td>
                <td>0.571</td>
                <td>0.259</td>
                <td>0.577</td>
                <td>0.486</td>
                <td>0.549</td>
                <td>0.442</td>
                <td>0.476</td>
                <td>0.475</td>
                <td>0.509</td>
                <td>0.566</td>
                <td>0.496</td>
                <td>0.439</td>
                <td>0.711</td>
                <td>0.546</td>
                <td>0.409</td>
                <td>0.436</td>
                <td>0.262</td>
                <td>0.570</td>
                <td>0.235</td>
              </tr>
              <tr>
                <td>Baichuan-13B-Chat</td>
                <td>0.450</td>
                <td>0.408</td>
                <td>0.491</td>
                <td>0.286</td>
                <td>0.552</td>
                <td>0.439</td>
                <td>0.670</td>
                <td>0.417</td>
                <td>0.422</td>
                <td>0.482</td>
                <td>0.486</td>
                <td>0.565</td>
                <td>0.505</td>
                <td>0.377</td>
                <td>0.704</td>
                <td>0.552</td>
                <td>0.387</td>
                <td>0.402</td>
                <td>0.350</td>
                <td>0.431</td>
                <td>0.304</td>
              </tr>
              <tr>
                <td>Chatglm3-6B</td>
                <td>0.436</td>
                <td>0.381</td>
                <td>0.439</td>
                <td>0.330</td>
                <td>0.541</td>
                <td>0.452</td>
                <td>0.577</td>
                <td>0.310</td>
                <td>0.358</td>
                <td>0.436</td>
                <td>0.453</td>
                <td>0.544</td>
                <td>0.503</td>
                <td>0.414</td>
                <td>0.762</td>
                <td>0.560</td>
                <td>0.446</td>
                <td>0.402</td>
                <td>0.321</td>
                <td>0.391</td>
                <td>0.270</td>
              </tr>
              <tr>
                <td>Yi-6B-Chat</td>
                <td>0.417</td>
                <td>0.402</td>
                <td>0.454</td>
                <td>0.313</td>
                <td>0.523</td>
                <td>0.425</td>
                <td>0.506</td>
                <td>0.383</td>
                <td>0.383</td>
                <td>0.487</td>
                <td>0.396</td>
                <td>0.523</td>
                <td>0.457</td>
                <td>0.369</td>
                <td>0.754</td>
                <td>0.482</td>
                <td>0.401</td>
                <td>0.380</td>
                <td>0.310</td>
                <td>0.455</td>
                <td>0.227</td>
              </tr>
              <tr>
                <td>Baichuan2-7B-Chat</td>
                <td>0.412</td>
                <td>0.437</td>
                <td>0.647</td>
                <td>0.160</td>
                <td>0.520</td>
                <td>0.402</td>
                <td>0.580</td>
                <td>0.511</td>
                <td>0.444</td>
                <td>0.455</td>
                <td>0.407</td>
                <td>0.489</td>
                <td>0.395</td>
                <td>0.406</td>
                <td>0.670</td>
                <td>0.517</td>
                <td>0.342</td>
                <td>0.298</td>
                <td>0.101</td>
                <td>0.463</td>
                <td>0.138</td>
              </tr>
              <tr>
                <td>Chatglm2-6B</td>
                <td>0.352</td>
                <td>0.278</td>
                <td>0.469</td>
                <td>0.346</td>
                <td>0.403</td>
                <td>0.424</td>
                <td>0.535</td>
                <td>0.274</td>
                <td>0.397</td>
                <td>0.406</td>
                <td>0.240</td>
                <td>0.397</td>
                <td>0.352</td>
                <td>0.326</td>
                <td>0.714</td>
                <td>0.438</td>
                <td>0.298</td>
                <td>0.313</td>
                <td>0.320</td>
                <td>0.461</td>
                <td>0.190</td>
              </tr>
              <tr>
                <td>Chatglm-6B-Sft</td>
                <td>0.349</td>
                <td>0.265</td>
                <td>0.454</td>
                <td>0.365</td>
                <td>0.385</td>
                <td>0.462</td>
                <td>0.554</td>
                <td>0.296</td>
                <td>0.379</td>
                <td>0.427</td>
                <td>0.232</td>
                <td>0.380</td>
                <td>0.321</td>
                <td>0.292</td>
                <td>0.718</td>
                <td>0.415</td>
                <td>0.296</td>
                <td>0.333</td>
                <td>0.351</td>
                <td>0.441</td>
                <td>0.190</td>
              </tr>
              <tr>
                <td>Chinese-Llama2-Linly-13B</td>
                <td>0.344</td>
                <td>0.250</td>
                <td>0.462</td>
                <td>0.311</td>
                <td>0.399</td>
                <td>0.429</td>
                <td>0.557</td>
                <td>0.273</td>
                <td>0.358</td>
                <td>0.385</td>
                <td>0.268</td>
                <td>0.390</td>
                <td>0.330</td>
                <td>0.313</td>
                <td>0.653</td>
                <td>0.433</td>
                <td>0.279</td>
                <td>0.332</td>
                <td>0.292</td>
                <td>0.457</td>
                <td>0.181</td>
              </tr>
              <tr>
                <td>Gpt-3.5-Turbo-Sft</td>
                <td>0.343</td>
                <td>0.269</td>
                <td>0.427</td>
                <td>0.298</td>
                <td>0.389</td>
                <td>0.395</td>
                <td>0.575</td>
                <td>0.325</td>
                <td>0.365</td>
                <td>0.389</td>
                <td>0.226</td>
                <td>0.382</td>
                <td>0.394</td>
                <td>0.345</td>
                <td>0.710</td>
                <td>0.433</td>
                <td>0.324</td>
                <td>0.266</td>
                <td>0.290</td>
                <td>0.397</td>
                <td>0.225</td>
              </tr>
              <tr>
                <td>Chinese-Alpaca-2-13B</td>
                <td>0.341</td>
                <td>0.242</td>
                <td>0.421</td>
                <td>0.356</td>
                <td>0.382</td>
                <td>0.442</td>
                <td>0.602</td>
                <td>0.256</td>
                <td>0.363</td>
                <td>0.430</td>
                <td>0.210</td>
                <td>0.376</td>
                <td>0.334</td>
                <td>0.317</td>
                <td>0.714</td>
                <td>0.459</td>
                <td>0.299</td>
                <td>0.316</td>
                <td>0.308</td>
                <td>0.452</td>
                <td>0.200</td>
              </tr>
              <tr>
                <td>Chinese-Alpaca-13B</td>
                <td>0.334</td>
                <td>0.250</td>
                <td>0.399</td>
                <td>0.348</td>
                <td>0.364</td>
                <td>0.435</td>
                <td>0.616</td>
                <td>0.275</td>
                <td>0.349</td>
                <td>0.421</td>
                <td>0.223</td>
                <td>0.370</td>
                <td>0.309</td>
                <td>0.319</td>
                <td>0.724</td>
                <td>0.426</td>
                <td>0.285</td>
                <td>0.307</td>
                <td>0.298</td>
                <td>0.445</td>
                <td>0.181</td>
              </tr>
              <tr>
                <td>Chinese-Alpaca-7B</td>
                <td>0.334</td>
                <td>0.216</td>
                <td>0.412</td>
                <td>0.378</td>
                <td>0.381</td>
                <td>0.425</td>
                <td>0.576</td>
                <td>0.265</td>
                <td>0.359</td>
                <td>0.393</td>
                <td>0.243</td>
                <td>0.383</td>
                <td>0.326</td>
                <td>0.295</td>
                <td>0.710</td>
                <td>0.409</td>
                <td>0.301</td>
                <td>0.327</td>
                <td>0.325</td>
                <td>0.405</td>
                <td>0.186</td>
              </tr>
              <tr>
                <td>Chinese-Llama2-Linly-7B</td>
                <td>0.333</td>
                <td>0.218</td>
                <td>0.451</td>
                <td>0.330</td>
                <td>0.396</td>
                <td>0.427</td>
                <td>0.583</td>
                <td>0.248</td>
                <td>0.350</td>
                <td>0.410</td>
                <td>0.231</td>
                <td>0.367</td>
                <td>0.345</td>
                <td>0.276</td>
                <td>0.698</td>
                <td>0.433</td>
                <td>0.259</td>
                <td>0.315</td>
                <td>0.310</td>
                <td>0.469</td>
                <td>0.168</td>
              </tr>
              <tr>
                <td>Tigerbot-13B-Chat</td>
                <td>0.331</td>
                <td>0.205</td>
                <td>0.397</td>
                <td>0.309</td>
                <td>0.385</td>
                <td>0.420</td>
                <td>0.614</td>
                <td>0.310</td>
                <td>0.379</td>
                <td>0.341</td>
                <td>0.276</td>
                <td>0.363</td>
                <td>0.329</td>
                <td>0.301</td>
                <td>0.694</td>
                <td>0.419</td>
                <td>0.280</td>
                <td>0.310</td>
                <td>0.283</td>
                <td>0.393</td>
                <td>0.186</td>
              </tr>
              <tr>
                <td>Telechat-7B</td>
                <td>0.329</td>
                <td>0.267</td>
                <td>0.338</td>
                <td>0.321</td>
                <td>0.420</td>
                <td>0.404</td>
                <td>0.420</td>
                <td>0.272</td>
                <td>0.265</td>
                <td>0.327</td>
                <td>0.320</td>
                <td>0.388</td>
                <td>0.355</td>
                <td>0.244</td>
                <td>0.672</td>
                <td>0.344</td>
                <td>0.334</td>
                <td>0.335</td>
                <td>0.299</td>
                <td>0.364</td>
                <td>0.184</td>
              </tr>
              <tr>
                <td>Ziya-Llama-13B</td>
                <td>0.329</td>
                <td>0.196</td>
                <td>0.402</td>
                <td>0.324</td>
                <td>0.341</td>
                <td>0.428</td>
                <td>0.616</td>
                <td>0.312</td>
                <td>0.349</td>
                <td>0.400</td>
                <td>0.228</td>
                <td>0.351</td>
                <td>0.279</td>
                <td>0.313</td>
                <td>0.721</td>
                <td>0.468</td>
                <td>0.311</td>
                <td>0.291</td>
                <td>0.278</td>
                <td>0.431</td>
                <td>0.175</td>
              </tr>
              <tr>
                <td>Chinese-Alpaca-33B</td>
                <td>0.326</td>
                <td>0.234</td>
                <td>0.370</td>
                <td>0.372</td>
                <td>0.364</td>
                <td>0.429</td>
                <td>0.614</td>
                <td>0.246</td>
                <td>0.318</td>
                <td>0.377</td>
                <td>0.221</td>
                <td>0.368</td>
                <td>0.300</td>
                <td>0.314</td>
                <td>0.713</td>
                <td>0.428</td>
                <td>0.288</td>
                <td>0.303</td>
                <td>0.295</td>
                <td>0.401</td>
                <td>0.199</td>
              </tr>
              <tr>
                <td>Tigerbot-7B-Chat</td>
                <td>0.325</td>
                <td>0.218</td>
                <td>0.395</td>
                <td>0.306</td>
                <td>0.370</td>
                <td>0.413</td>
                <td>0.631</td>
                <td>0.294</td>
                <td>0.370</td>
                <td>0.368</td>
                <td>0.215</td>
                <td>0.355</td>
                <td>0.313</td>
                <td>0.292</td>
                <td>0.713</td>
                <td>0.415</td>
                <td>0.283</td>
                <td>0.315</td>
                <td>0.290</td>
                <td>0.389</td>
                <td>0.171</td>
              </tr>
              <tr>
                <td>Chinese-Alpaca-2-7B</td>
                <td>0.323</td>
                <td>0.215</td>
                <td>0.374</td>
                <td>0.335</td>
                <td>0.366</td>
                <td>0.415</td>
                <td>0.546</td>
                <td>0.257</td>
                <td>0.326</td>
                <td>0.395</td>
                <td>0.215</td>
                <td>0.375</td>
                <td>0.318</td>
                <td>0.289</td>
                <td>0.698</td>
                <td>0.417</td>
                <td>0.285</td>
                <td>0.303</td>
                <td>0.312</td>
                <td>0.439</td>
                <td>0.193</td>
              </tr>
              <tr>
                <td>Aquilachat-7B</td>
                <td>0.309</td>
                <td>0.162</td>
                <td>0.234</td>
                <td>0.291</td>
                <td>0.320</td>
                <td>0.437</td>
                <td>0.344</td>
                <td>0.135</td>
                <td>0.266</td>
                <td>0.309</td>
                <td>0.287</td>
                <td>0.337</td>
                <td>0.342</td>
                <td>0.236</td>
                <td>0.609</td>
                <td>0.255</td>
                <td>0.249</td>
                <td>0.400</td>
                <td>0.527</td>
                <td>0.430</td>
                <td>0.306</td>
              </tr>
              <tr>
                <td>Moss-Moon-003-Sft</td>
                <td>0.302</td>
                <td>0.214</td>
                <td>0.405</td>
                <td>0.274</td>
                <td>0.347</td>
                <td>0.380</td>
                <td>0.448</td>
                <td>0.305</td>
                <td>0.341</td>
                <td>0.378</td>
                <td>0.232</td>
                <td>0.317</td>
                <td>0.321</td>
                <td>0.267</td>
                <td>0.694</td>
                <td>0.375</td>
                <td>0.251</td>
                <td>0.259</td>
                <td>0.288</td>
                <td>0.424</td>
                <td>0.152</td>
              </tr>
              <tr>
                <td>Qwen-7B-Chat</td>
                <td>0.301</td>
                <td>0.211</td>
                <td>0.410</td>
                <td>0.289</td>
                <td>0.349</td>
                <td>0.391</td>
                <td>0.531</td>
                <td>0.219</td>
                <td>0.387</td>
                <td>0.404</td>
                <td>0.208</td>
                <td>0.325</td>
                <td>0.297</td>
                <td>0.278</td>
                <td>0.681</td>
                <td>0.419</td>
                <td>0.266</td>
                <td>0.251</td>
                <td>0.248</td>
                <td>0.371</td>
                <td>0.157</td>
              </tr>
              <tr>
                <td>Belle-13B-Sft</td>
                <td>0.264</td>
                <td>0.198</td>
                <td>0.307</td>
                <td>0.285</td>
                <td>0.316</td>
                <td>0.349</td>
                <td>0.409</td>
                <td>0.237</td>
                <td>0.305</td>
                <td>0.222</td>
                <td>0.177</td>
                <td>0.317</td>
                <td>0.284</td>
                <td>0.242</td>
                <td>0.631</td>
                <td>0.299</td>
                <td>0.244</td>
                <td>0.222</td>
                <td>0.234</td>
                <td>0.296</td>
                <td>0.133</td>
              </tr>
              <tr>
                <td>Cpm-Bee-10B</td>
                <td>0.244</td>
                <td>0.234</td>
                <td>0.377</td>
                <td>0.024</td>
                <td>0.278</td>
                <td>0.311</td>
                <td>0.255</td>
                <td>0.302</td>
                <td>0.278</td>
                <td>0.327</td>
                <td>0.148</td>
                <td>0.286</td>
                <td>0.224</td>
                <td>0.147</td>
                <td>0.603</td>
                <td>0.277</td>
                <td>0.117</td>
                <td>0.263</td>
                <td>0.220</td>
                <td>0.352</td>
                <td>0.125</td>
              </tr>
            </tbody>
          </table>
          </div>

      </div>
    </div>
    <!-- <div class="columns is-centered m-6">
      <div class="column is-max-desktop has-text-centered">
        <h2 class="title is-3" id="visualization">Visualization</h2>
        <iframe src="visualizer/explore.html" style="width: 100%;min-height: 100vh; border-radius: 20px;"></iframe>
      </div>
    </div> -->
  </div>
</section>

<!-- RESULTS SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <h1 class="title is-1 mmmu">Experiment Results</h1>
  </div>
</section>
<section class="section">
  <div class="container">



<!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
        <div class="content">
          <div class="content has-text-justified">
            <p>
              As the CIF-Bench aims to provide a comprehensive evaluation of the LLM instruction-following capability, we argue that the metrics should be designed case by case in task granularity to evaluate the open-ended textual outputs, rather than simply reformatting all tasks into choice questions and using the conditional probability to approximate the models' predictions.
            </p>
            <p>
              After a thorough review of the task instructions, we categorize the output requirements into the four following types and design corresponding task-level metrics. Multi-class Classification: We use accuracy as the metric if the task requires the model to predict one label from 2 or more classes in the output. Multi-label Classification: We use F1 score as the metric if the task requires the model to predict one label from 2 or more classes in the output. Creative Generation: Regarding the tasks that have no absolute criteria of the standard answer, we require a model-based evaluator to provide information regarding a given output, including creativity, fluency, the level of instruction-following, and the confidence of the evaluator. Semantic Similarity: For the remaining tasks that can be evaluated by the semantic similarity between the golden reference and model output, we use a pre-trained language. All scores used in CIF-Bench either naturally range from 0 to 1, or are normalized to the same range.
            </p>
            <p>
              One core dilemma in evaluating the open-ended instruction-following capabilities of LLMs is that model predictions are hard to verify even with reference answers. For instance, it is intractable to handcraft regex rules to extract the predictions from LLMs for the extensive number of tasks, since the answers could be expressed in various formats, or drowned in redundant contexts like reasoning progress. Inspired by G-Eval, we leverage OpenAI's GPT-4 as a relatively reliable evaluator for multi-class classification, multi-label classification, and creative generation tasks, to overcome such issues. The GPT-4 evaluator is prompted to assess the outputs according to the given task instruction and the input-output reference. For the answers that can be evaluated with semantic similarity, we use a lightweight multilingual encoder, BLEURT, to measure the relevance between the reference and LLM output. 
            </p>
              Given a set of task instructions <script type="math/tex">I</script>, we denote the performance score of model <script type="math/tex">m</script> on task <script type="math/tex">t</script> as: <script type="math/tex">S^{m}_{t}=\frac{1}{|D_t|}\sum_{d \in D_t}\frac{1}{|I|}\sum_{i \in I}{{s^{m}_{t}(i,d)}}</script>, where <script type="math/tex">D_t</script> refers to the set of data samples for task <script type="math/tex">t</script>. In the case of the public split, the instruction set <script type="math/tex">I</script> is reduced to one single element. In we take the average of task-level scores <script type="math/tex">\overline{S^m}</script> as the indicator of overall performance for a model <script type="math/tex">m</script>.
            </p>
          </div>

          <div class="model-labels-container">
            <!-- <span class="leaderboard-label" style="background-color: #f8fffe;">Open-Source</span>
            <span class="leaderboard-label" style="background-color: #f9f2f8;">Closed</span> -->

            <span class="leaderboard-label" style="background-color: #e4efdc;">Multimodal</span>
            <span class="leaderboard-label" style="background-color: #e0ebf3;">Language-Only</span>
            <span class="leaderboard-label" style="background-color: #def9cb;">Proprietary</span>

          </div>
          <table id="table1" class="js-sort-table">
            <tr>
              <td class="js-sort-number"><strong>Reset</strong></td>
              <td class="js-sort-number"><strong>Test Overall</strong></td>
              <td class="js-sort-number"><strong>Validation Overall</strong></td>
              <td class="js-sort-number"><strong>Art & Design</strong></td>
              <td class="js-sort-number"><strong>Business</strong></td>
              <td class="js-sort-number"><strong>Science</strong></td>
              <td class="js-sort-number"><strong>Health & Medicine</strong></td>
              <td class="js-sort-number"><strong>Human & Social Sci.</strong></td>
              <td class="js-sort-number"><strong>Tech & Eng.</strong></td>
            </tr>
              <tr style="background-color: #def9cb;">
                <td style="text-align: left;">
                    <b> GPT-4V </b>
                </td>
                <td> <b>43.7</b> </td>
                <td> <b>42.5</b> </td>
                
                <td> 61.0 </td>
                <td> <b>36.3</b> </td>
                <td> <b>40.9</b> </td>
                <td> <b>46.8</b> </td>
                <td> <b>44.2</b> </td>
                <td> <b>41.5</b> </td>
              </tr>
              <tr style="background-color: #def9cb;">
                <td style="text-align: left;">
                        <b>Qwen-VL-Plus </b>
                </td>
                <td> 36.8 </td>
                <td> 39.5 </td>
                
                <td> 61.5 </td>
                <td> 23.2 </td>
                <td> 32.8 </td>
                <td> 40.5 </td>
                <td> 43.4 </td>
                <td> 33.3 </td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                        <b> Yi-VL-34B </b>
                  </td>
              <td style="text-decoration: underline;"> 36.5 </td>
                  <td style="text-decoration: underline;"> 36.2 </td>
              
              <td style="text-decoration: underline;"> <b>62.9</b> </td>
              <td> 19.1 </td>
              <td> 31.5 </td>
              <td style="text-decoration: underline;"> 42.1 </td>
              <td style="text-decoration: underline;"> 42.5 </td>
              <td style="text-decoration: underline;"> 34.5 </td> 
              </tr> 
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                        <b> Yi-VL-6B </b>
                </td>
              <td> 35.0 </td>
                <td> 35.8 </td>
              
              <td> 58.0 </td>
              <td> 19.9 </td>
              <td style="text-decoration: underline;"> 32.3 </td>
              <td> 39.3 </td>
              <td> 40.6 </td>
              <td> 32.1 </td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                      <b>InternVL-Chat-V1.1</b>
                </td>
                <td>34.0</td>
                <td>34.7</td>
                
                <td>56.7</td>
                <td>19.7</td>
                <td>28.6</td>
                <td>39.2</td>
                <td>39.6</td>
                <td>32.3</td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                      <b>Qwen-VL-Chat</b>
                </td>
                <td>31.3</td>
                <td>30.7</td>
                
                <td>52.6</td>
                <td>18.5</td>
                <td>26.9</td>
                <td>33.4</td>
                <td>34.1</td>
                <td>31.4</td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                      <b>SPHINX-MoE</b>
                </td>
                <td>29.5</td>
                <td>29.3</td>
                
                <td>41.7</td>
                <td style="text-decoration: underline;">20.3</td>
                <td>27.8</td>
                <td>28.9</td>
                <td>31.8</td>
                <td>30.9</td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                      <b>InternVL-Chat-ViT-6B-Vicuna-7B</b>
                </td>
                <td>26.7</td>
                <td>26.4</td>
                
                <td>39.7</td>
                <td>13.8</td>
                <td>23.0</td>
                <td>31.7</td>
                <td>26.5</td>
                <td>28.5</td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                      <b>InternVL-Chat-ViT-6B-Vicuna-13B</b>
                </td>
                <td>26.1</td>
                <td>27.4</td>
                
                <td>38.5</td>
                <td>13.9</td>
                <td>22.1</td>
                <td>30.2</td>
                <td>29.8</td>
                <td>27.5</td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                      <b>Emu2-Chat</b>
                </td>
                <td>24.5</td>
                <td>23.8</td>
                
                <td>35.3</td>
                <td>11.7</td>
                <td>22.1</td>
                <td>25.5</td>
                <td>28.0</td>
                <td>27.1</td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                      <b>CogAgent-Chat</b>
                </td>
                <td>23.6</td>
                <td>24.6</td>
                
                <td>33.8</td>
                <td>14.1</td>
                <td>20.6</td>
                <td>26.3</td>
                <td>24.8</td>
                <td>25.3</td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                      <b>Chinese-LLaVa</b>
                </td>
                <td>23.4</td>
                <td>25.5</td>
                
                <td>34.4</td>
                <td>11.7</td>
                <td>21.6</td>
                <td>25.5</td>
                <td>26.3</td>
                <td>24.7</td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                      <b>VisCPM</b>
                </td>
                <td>22.7</td>
                <td>25.2</td>
                
                <td>37.7</td>
                <td>11.3</td>
                <td>19.1</td>
                <td>26.1</td>
                <td>24.0</td>
                <td>23.7</td>
              </tr>
              <tr style="background-color: #e4efdc;">
                <td style="text-align: left;">
                      <b>mPLUG-Owl2</b>
                </td>
                <td>22.2</td>
                <td>20.8</td>
                
                <td>30.4</td>
                <td>13.3</td>
                <td>19.6</td>
                <td>25.2</td>
                <td>24.7</td>
                <td>23.4</td>
              </tr>


              <tr style="background-color: #e0ebf3;">
                <td style="text-align: left;">
                        <b> Yi-6B + OCR </b>
                </td>
              <td> 26.8 </td>
                <td> 28.4 </td>
              
              <td> 33.4 </td>
              <td> 16.9 </td>
              <td> 24.8 </td>
              <td> 32.3 </td>
              <td> 33.2 </td>
              <td> 25.5 </td>
              </tr>
              <tr style="background-color: #e0ebf3;">
                  <td style="text-align: left;">
                          <b> Qwen-7B + OCR </b>
                  </td>
              <td> 26.1 </td>
                  <td> 27.0 </td>
              
              <td> 44.6 </td>
              <td> 14.3 </td>
              <td> 22.1 </td>
              <td> 29.3 </td>
              <td> 29.8 </td>
              <td> 25.4 </td>
              </tr>
              <tr style="background-color: #e0ebf3;">
                <td style="text-align: left;">
                        <b> Qwen-7B </b>
                </td>
              <td> 25.1 </td>
                <td> 24.7 </td>
              
              <td> 43.8 </td>
              <td> 12.6 </td>
              <td> 20.7 </td>
              <td> 30.5 </td>
              <td> 26.9 </td>
              <td> 24.5 </td>
              </tr>
              <tr style="background-color: #e0ebf3;">
                  <td style="text-align: left;">
                          <b> Baichuan-7B + OCR </b>
                  </td>
              <td> 24.7 </td>
                  <td> 25.3 </td>
              
              <td> 40.2 </td>
              <td> 15.2 </td>
              <td> 21.0 </td>
              <td> 27.9 </td>
              <td> 30.7 </td>
              <td> 22.8 </td>
              </tr>
              <tr style="background-color: #e0ebf3;">
                  <td style="text-align: left;">
                          <b> Baichuan-7B </b>
                  </td>
              <td> 24.3 </td>
                  <td> 26.0 </td>
              
              <td> 42.7 </td>
              <td> 12.6 </td>
              <td> 19.6 </td>
              <td> 28.0 </td>
              <td> 27.8 </td>
              <td> 23.9 </td>
              </tr>
              
              
              
              <tr style="background-color: #e0ebf3;">
                  <td style="text-align: left;">
                          <b> Yi-6B </b>
                  </td>
              <td> 24.2 </td>
                  <td> 25.6 </td>
              
              <td> 26.3 </td>
              <td> 15.0 </td>
              <td> 23.4 </td>
              <td> 29.1 </td>
              <td> 27.0 </td>
              <td> 24.7 </td>
              </tr>
              
              <tr style="background-color: #e0ebf3;">
                  <td style="text-align: left;">
                          <b> DeepSeek-7B + OCR </b>
                  </td>
              <td> 23.2 </td>
                  <td> 25.2 </td>
              
              <td> 41.2 </td>
              <td> 13.2 </td>
              <td> 19.4 </td>
              <td> 26.1 </td>
              <td> 26.5 </td>
              <td> 21.8 </td>
              </tr>
              <tr style="background-color: #e0ebf3;">
                <td style="text-align: left;">
                        <b> DeepSeek-7B </b>
                </td>
            <td> 21.9 </td>
                <td> 22.3 </td>
            
            <td> 41.3 </td>
            <td> 11.2 </td>
            <td> 18.3  </td>
            <td> 23.5 </td>
            <td> 24.7 </td>
            <td> 21.3 </td>
            </tr>
            <tr style="background-color: white;">
              <td style="text-align: left;">
                    <b>Frequent Choice</b>
              </td>
              <td>26.0</td>
              <td>24.1</td>
              
              <td>36.2</td>
              <td>11.8</td>
              <td>23.9</td>
              <td>30.2</td>
              <td>28.5</td>
              <td>27.7</td>
            </tr>
              <tr style="background-color: white;">
                <td style="text-align: left;">
                      <b>Random Choice</b>
                </td>
                <td>21.6</td>
                <td>21.6</td>
                
                <td>32.9</td>
                <td>9.1</td>
                <td>18.8</td>
                <td>23.8</td>
                <td>23.8</td>
                <td>23.9</td>
              </tr>
            <!-- <tr>
              <td colspan="8" style="font-size: 18px;"><b>Large Language Models (LLMs): Only Text as Input</b></td>
            </tr>               -->
            <!-- <tr style="background-color: #f8fffe;">
              <td style="text-align: left;"><b>Llama2 7B</b></td>
              <td>28.7</td>
              <td>30.7</td>
              <td>27.2</td>
              <td>26.7</td>
              <td>27.7</td>
              <td>32.6</td>
              <td>29.8</td>
            </tr>
            <tr style="background-color: #f4fdf5;">
              <td style="text-align: left;"><b>FLAN-T5-XXL</b></td>
              <td><b>31.2</b></td>
              <td>36.8</td>
              <td><b>28.9</b></td>
              <td>26.7</td>
              <td>32.8</td>
              <td><b>44.8</b></td>
              <td><b>28.3</b></td>
            </tr>
            <tr style="background-color: #f4fdf5;">
              <td style="text-align: left;"><b>FLAN-T5-XXL + OCR</b></td>
              <td><b>31.9</b></td>
              <td>36.2</td>
              <td>28.8</td>
              <td>26.2</td>
              <td>32.6</td>
              <td><b>50.5</b></td>
              <td><b>29.7</b></td>
            </tr>
            <tr style="background-color: #f4fdf5;">
              <td style="text-align: left;"><b>FLAN-T5-XXL + LLaVA Caption</b></td>
              <td><b>31.9</b></td>
              <td><b>38.4</b></td>
              <td>27.8</td>
              <td><b>27.0</b></td>
              <td><b>33.2</b></td>
              <td>49.9</td>
              <td>28.7</td>
            </tr>
            <tr style="background-color: #e7fde9;">
              <td style="text-align: left;"><b>Vicuna-13B</b></td>
              <td>31.0</td>
              <td>35.1</td>
              <td><b>30.1</b></td>
              <td>24.7</td>
              <td>31.4</td>
              <td>44.8</td>
              <td>30.1</td>
            </tr>
            <tr style="background-color: #e7fde9;">
              <td style="text-align: left;"><b>Vicuna-13B + OCR</b></td>
              <td>31.9</td>
              <td>37.1</td>
              <td>28.6</td>
              <td><b>26.5</b></td>
              <td>32.0</td>
              <td>49.3</td>
              <td>30.0</td>
            </tr>
            <tr style="background-color: #e7fde9;">
              <td style="text-align: left;"><b>Vicuna-13B + LLaVA Caption</b></td>
              <td><b>32.7</b></td>
              <td><b>42.0</b></td>
              <td>26.8</td>
              <td>26.2</td>
              <td><b>33.4</b></td>
              <td><b>49.4</b></td>
              <td><b>31.4</b></td>
            </tr> -->
            <!-- <tr style="background-color: #f8fffe;">
              <td style="text-align: left;"><b>GPT-4 Text</b></td>
              <td>33.8</td>
              <td>32.9</td>
              <td>28.5</td>
              <td>30.6</td>
              <td>41.3</td>
              <td>53.0</td>
              <td>28.4</td>
            </tr> -->
          </table>

            <p> Overall results of different models on the CMMMU test set. The best-performing model is <b>in-bold</b>, and the best open-source model is <u>underlined</u>. </p> 
        </div>
      </div>
    </div>

<!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->


  </div>
</section>


<!-- @PAN TODO: bibtex -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre><code>
      @article{cif-bench,}
</code></pre>
  </div>
</section>

<footer class="footer">
  <!-- <div class="container"> -->
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is website adapted from <a href=https://cmmmu-benchmark.github.io/">CMMMU</a>, licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  <!-- </div> -->

</footer>

<script>
  // function changeButtonText() {
  //   var button = document.getElementById('toggleButton');
  //   if (button.innerHTML.includes("Test Set Leaderboard")) {
  //     button.innerHTML = "<b style='font-size: larger;'>Validation Set Leaderboard</b> (Click to Switch)";
  //   } else {
  //     button.innerHTML = "<b style='font-size: larger;'>Test Set Leaderboard</b> (Click to Switch)";
  //   }
  // }
  document.addEventListener('DOMContentLoaded', function() {
    var tables = document.querySelectorAll('table');
    
    tables.forEach(function(table) {
        if (!table) return;

        var initialRows = Array.from(table.rows).slice(1);
        table.addEventListener('click', function(event) {
            var clickedCell = event.target.closest('td, th');
            if (!clickedCell) return;
            var headerRow = clickedCell.parentNode;
            var columnIndex = Array.from(headerRow.cells).indexOf(clickedCell);
            var type = clickedCell.getAttribute('data-type');

            if (headerRow.rowIndex === 0) {
                if (columnIndex === 0) {
                    table.tBodies[0].innerHTML = '';
                    initialRows.forEach(row => table.tBodies[0].appendChild(row.cloneNode(true)));
                }
            }
        });
    });
});

function sortTable(table, column, type, asc) {
    var tbody = table.tBodies[0];
    var rows = Array.from(tbody.rows);

    rows.sort(function(a, b) {
        var valA = a.cells[column].textContent;
        var valB = b.cells[column].textContent;

        if (type === 'number') {
            valA = parseFloat(valA);
            valB = parseFloat(valB);
        }

        return asc ? valA - valB : valB - valA;
    });

    rows.forEach(row => tbody.appendChild(row));
}

  // 切换表格的函数
  // function toggleTables () {
  //     var table1 = document.getElementById('table1');
  //     var table2 = document.getElementById('table2');
  //     table1.classList.toggle('hidden');
  //     table2.classList.toggle('hidden');
  // }

  document.getElementById('toggleButton').addEventListener('click', toggleTables);
  const canvas = document.getElementById('difficulty_level_chart');
  canvas.style.width = '500px';
  canvas.style.height = '120px';
  const ctx = document.getElementById('difficulty_level_chart').getContext('2d');
  const difficulty_level_chart = new Chart(ctx, {
    type: 'bar',
    data: {
      labels: ['Easy', 'Medium', 'Hard', 'Overall'],
      datasets: [{
        label: 'Fuyu-8B',
        data: [28.9, 27, 26.4, 27.4],
        backgroundColor: 'rgba(196, 123, 160, 0.6)',
        borderColor: 'rgba(196, 123, 160, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(196, 123, 160, 1)'
      },
      {
        label: 'Qwen-VL-7B',
        data: [39.4, 31.9, 27.6, 32.9],
        backgroundColor: 'rgba(245, 123, 113, 0.6)',
        borderColor: 'rgba(245, 123, 113, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(245, 123, 113, 1)'
      },
      {
        label: 'LLaVA-1.5-13B',
        data: [41.3, 32.7, 26.7, 33.6],
        backgroundColor: 'rgba(255, 208, 80, 0.6)',
        borderColor: 'rgba(255, 208, 80, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 208, 80, 1)'
      },
      {
        label: 'InstructBLIP-T5-XXL',
        data: [40.3, 32.3, 29.4, 33.8],
        backgroundColor: 'rgba(110, 194, 134, 0.6)',
        borderColor: 'rgba(110, 194, 134, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(110, 194, 134, 1)'
      },
      {
        label: 'BLIP-2 FLAN-T5-XXL',
        data: [41, 32.7, 28.5, 34],
        backgroundColor: 'rgba(255, 153, 78, 0.6)',
        borderColor: 'rgba(255, 153, 78, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 153, 78, 1)'
      },
      {
        label: 'GPT-4V',
        data: [76.1, 55.6, 31.2, 55.7],
        backgroundColor: 'rgba(117, 209, 215, 0.6)',
        borderColor: 'rgba(117, 209, 215, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(117, 209, 215, 1)'
      }]
    },
    options: {
    scales: {
      y: {
        beginAtZero: true,
        min: 0,     
        max: 100,
        ticks: {
          stepSize: 20,
          font: {
            size: 16
          }
        }
      },
      x: {
        ticks: {
          font: {
            size: 16 // 设置X轴字体大小
          }
        }
      }
    },
    plugins: {
      legend: {
        labels: {
          font: {
            size: 16 // 设置标签文字大小
          }
        }
      },
      tooltip: {
        callbacks: {
          label: function(context) {
            return context.dataset.label + ': ' + context.parsed.y;
          }
        }
      }
    },
      onHover: (event, chartElement) => {
        event.native.target.style.cursor = chartElement[0] ? 'pointer' : 'default';
      }
    }
  });
  document.addEventListener('DOMContentLoaded', function() {
    // Data for the "Diagrams" chart
    const data_Diagrams = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.6, 30.1, 31.8, 30.0, 32.0, 46.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };

    // "data_Diagrams" chart
    new Chart(document.getElementById('chart_Diagrams'), {
        type: 'bar',
        data: data_Diagrams,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Tables" chart
    const data_Tables  = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [26.6, 29.0, 29.8, 27.8, 27.8, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Tables'), {
        type: 'bar',
        data: data_Tables,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_PlotsAndCharts " chart
    const data_PlotsAndCharts   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [24.8, 31.8, 36.2, 30.4, 35.8, 55.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PlotsAndCharts'), {
        type: 'bar',
        data: data_PlotsAndCharts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_ChemicalStructures " chart
    const data_ChemicalStructures   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [25.0, 27.2, 27.1, 26.7, 25.5, 50.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ChemicalStructures'), {
        type: 'bar',
        data: data_ChemicalStructures ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Photographs " chart
    const data_Photographs   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.6, 40.5, 41.4, 44.4, 42.0, 64.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Photographs'), {
        type: 'bar',
        data: data_Photographs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Paintings " chart
    const data_Paintings   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [28.7, 57.2, 53.6, 56.3, 52.1, 75.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Paintings'), {
        type: 'bar',
        data: data_Paintings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_GeometricShapes " chart
    const data_GeometricShapes   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.1, 25.3, 21.4, 25.6, 28.3, 40.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_GeometricShapes'), {
        type: 'bar',
        data: data_GeometricShapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_SheetMusic " chart
    const data_SheetMusic   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [35.2, 33.4, 34.6, 35.8, 34.9, 38.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SheetMusic'), {
        type: 'bar',
        data: data_SheetMusic ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_MedicalImages " chart
    const data_MedicalImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [25.4, 29.8, 31.6, 36.4, 29.8, 59.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MedicalImages'), {
        type: 'bar',
        data: data_MedicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_PathologicalImages " chart
    const data_PathologicalImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [26.5, 27.7, 31.2, 35.2, 35.6, 63.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PathologicalImages'), {
        type: 'bar',
        data: data_PathologicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_MicroscopicImages " chart
    const data_MicroscopicImages   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [27.0, 37.6, 29.2, 36.3, 32.7, 58.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MicroscopicImages'), {
        type: 'bar',
        data: data_MicroscopicImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_MRIsCTScansXrays " chart
    const data_MRIsCTScansXrays   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.7, 36.9, 33.3, 39.4, 29.8, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MRIsCTScansXrays'), {
        type: 'bar',
        data: data_MRIsCTScansXrays ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_SketchesAndDrafts " chart
    const data_SketchesAndDrafts   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [37.0, 32.1, 29.9, 38.0, 33.7, 55.4],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SketchesAndDrafts'), {
        type: 'bar',
        data: data_SketchesAndDrafts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Maps " chart
    const data_Maps   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.2, 36.5, 45.9, 47.6, 43.5, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Maps'), {
        type: 'bar',
        data: data_Maps ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_TechnicalBlueprints " chart
    const data_TechnicalBlueprints   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [24.7, 25.9, 28.4, 25.3, 27.8, 38.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TechnicalBlueprints'), {
        type: 'bar',
        data: data_TechnicalBlueprints ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_TreesAndGraphs " chart
    const data_TreesAndGraphs   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.1, 28.1, 28.8, 28.8, 34.9, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TreesAndGraphs'), {
        type: 'bar',
        data: data_TreesAndGraphs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_MathematicalNotations " chart
    const data_MathematicalNotations   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [15.8, 27.1, 22.6, 21.8, 21.1, 45.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MathematicalNotations'), {
        type: 'bar',
        data: data_MathematicalNotations ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_ComicsAndCartoons " chart
    const data_ComicsAndCartoons   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [29.0, 51.9, 49.6, 54.2, 51.1, 68.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ComicsAndCartoons'), {
        type: 'bar',
        data: data_ComicsAndCartoons ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Sculpture " chart
    const data_Sculpture   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.8, 46.2, 49.6, 51.3, 53.0, 76.1],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Sculpture'), {
        type: 'bar',
        data: data_Sculpture ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Portraits " chart
    const data_Portraits   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [20.9, 52.7, 46.2, 54.9, 47.3, 70.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Portraits'), {
        type: 'bar',
        data: data_Portraits ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Screenshots " chart
    const data_Screenshots   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.6, 35.7, 38.6, 34.3, 47.1, 65.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Screenshots'), {
        type: 'bar',
        data: data_Screenshots ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Other " chart
    const data_Other   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [28.3, 38.3, 50.0, 51.7, 58.3, 68.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Other'), {
        type: 'bar',
        data: data_Other ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Poster " chart
    const data_Poster   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [38.6, 50.9, 52.6, 61.4, 64.9, 80.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Poster'), {
        type: 'bar',
        data: data_Poster ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_IconsAndSymbols " chart
    const data_IconsAndSymbols   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [23.8, 66.7, 57.1, 59.5, 59.5, 78.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_IconsAndSymbols'), {
        type: 'bar',
        data: data_IconsAndSymbols ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_HistoricalTimelines " chart
    const data_HistoricalTimelines   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.0, 36.7, 40.0, 43.3, 43.3, 63.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_HistoricalTimelines'), {
        type: 'bar',
        data: data_HistoricalTimelines ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_3DRenderings " chart
    const data_3DRenderings   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [33.3, 28.6, 57.1, 38.1, 47.6, 47.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_3DRenderings'), {
        type: 'bar',
        data: data_3DRenderings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_DNASequences " chart
    const data_DNASequences   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [20.0, 45.0, 25.0, 25.0, 45.0, 55.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_DNASequences'), {
        type: 'bar',
        data: data_DNASequences ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Landscapes " chart
    const data_Landscapes   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [43.8, 43.8, 50.0, 31.2, 62.5, 68.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Landscapes'), {
        type: 'bar',
        data: data_Landscapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_LogosAndBranding " chart
    const data_LogosAndBranding   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [21.4, 57.1, 64.3, 35.7, 50.0, 85.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_LogosAndBranding'), {
        type: 'bar',
        data: data_LogosAndBranding ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_Advertisements " chart
    const data_Advertisements   = {
        labels: ['Fuyu-8B', 'Qwen-VL-7B', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'GPT-4V'],
        datasets: [{
            data: [30.0, 60.0, 50.0, 60.0, 70.0, 100.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Advertisements'), {
        type: 'bar',
        data: data_Advertisements ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
});

</script>

<style>
  .hidden {
      display: none;
  }
  .sortable:hover {
      cursor: pointer;
  }
  .asc::after {
      content: ' ↑';
  }
  .desc::after {
      content: ' ↓';
  }
  #toggleButton {
    background-color: #ffffff;
    border: 1px solid #dddddd;
    color: #555555;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 14px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 25px; 
    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    transition-duration: 0.4s;
  }

  #toggleButton:hover {
    box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19); /* 鼠标悬停时的阴影效果 */
  }

  table {
    border-collapse: collapse;
    width: 100%;
    margin-top: 5px;
    border: 1px solid #ddd;
    font-size: 14px;
  }

  th, td {
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
      border-bottom: 2px solid #ddd;
  }

  td:hover {background-color: #ffffff;}
</style>

</body>
</html>
